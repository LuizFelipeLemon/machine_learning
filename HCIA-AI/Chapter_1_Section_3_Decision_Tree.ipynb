{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Chapter 1 - Section 3 - Decision Tree.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Ot9RalQ1y-2w"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuizFelipeLemon/machine_learning/blob/master/HCIA-AI/Chapter_1_Section_3_Decision_Tree.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F1rYq-5JObmp"
      },
      "source": [
        "# 3 Decision Tree"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fN9UZCOyWV5"
      },
      "source": [
        "## 3.1 Introduction\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVF9snF8PS9K"
      },
      "source": [
        "### 3.1.1 About This Experiment\n",
        "This experiment focuses on the decision tree algorithm through the basic Python code.\n",
        "\n",
        "It mainly uses Numpy module, Pandas module and Math module. We will implement the\n",
        "CART tree(Classification and Regressiontree models) in this experiment.\n",
        "\n",
        "You have to download the dataset before this experiment through this link:\n",
        "https://data-certification.obs.cn-east-2.myhuaweicloud.com/ENG/HCIA-AI/V3.0/ML-Dataset.rar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KmWqQiNuPPWP"
      },
      "source": [
        "### 3.1.2 Objectives\n",
        "The purpose of this experiment is as follows:\n",
        "- Familiar with basic Python syntax\n",
        "- Master the principle of Classification tree and implement with Python code\n",
        "- Master the principle of Regression tree and implement with Python code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8U99-9xyk4M"
      },
      "source": [
        "## 3.2 Experiment Code\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RW31HcrVysYv"
      },
      "source": [
        "### 3.2.1 Import the modules you need \n",
        "\n",
        "- Pandas is a tabular data processing module.\n",
        "- Math is mainly used for mathematical calculations.\n",
        "- Numpy is the basic computing module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bW7X7qzIwQjN"
      },
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubSbTpoQ5Mxj"
      },
      "source": [
        "#### Loading DataSet\n",
        "- Golf.txt for classification\n",
        "- Golf4.txt for regression\n",
        "\n",
        "You have to download the dataset before: https://data-certification.obs.cn-east-2.myhuaweicloud.com/ENG/HCIA-AI/V3.0/ML-Dataset.rar"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qzdm6MN5Ls_",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 260
        },
        "outputId": "665c755c-024e-43d4-b357-08fd22e83713"
      },
      "source": [
        "from google.colab import files\n",
        "data=files.upload()\n",
        "import io\n",
        "# Dataset1: Text features and text labels\n",
        "#df = pd.read_csv(io.BytesIO(data['golf.txt']))\n",
        "# Dataset2: Mix features and Numeric labels, here you have to change the path to yours. \n",
        "df = pd.read_csv(io.BytesIO(data['golf4.txt']))\n",
        "df.head()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-6d68df9e-e236-4089-908c-7e52c902a0f0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-6d68df9e-e236-4089-908c-7e52c902a0f0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving golf4.txt to golf4 (3).txt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Outlook</th>\n",
              "      <th>Temp.</th>\n",
              "      <th>Humidity</th>\n",
              "      <th>Wind</th>\n",
              "      <th>Decision</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sunny</td>\n",
              "      <td>85</td>\n",
              "      <td>85</td>\n",
              "      <td>Weak</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sunny</td>\n",
              "      <td>80</td>\n",
              "      <td>90</td>\n",
              "      <td>Strong</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Overcast</td>\n",
              "      <td>83</td>\n",
              "      <td>78</td>\n",
              "      <td>Weak</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Rain</td>\n",
              "      <td>70</td>\n",
              "      <td>96</td>\n",
              "      <td>Weak</td>\n",
              "      <td>46</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Rain</td>\n",
              "      <td>68</td>\n",
              "      <td>80</td>\n",
              "      <td>Weak</td>\n",
              "      <td>52</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Outlook  Temp.  Humidity    Wind  Decision\n",
              "0     Sunny     85        85    Weak        25\n",
              "1     Sunny     80        90  Strong        30\n",
              "2  Overcast     83        78    Weak        46\n",
              "3      Rain     70        96    Weak        46\n",
              "4      Rain     68        80    Weak        52"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Dm9JEWe63Q7"
      },
      "source": [
        "**Optional:** Another way to read dataset uploaded to GDrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bf7qRJMV3xvg"
      },
      "source": [
        "from google.colab import drive\n",
        "#You must uncomment this line in the first time to mount your gdrive\n",
        "#Tutorial (section B): https://medium.com/@simonprdhm/2-ways-to-upload-csv-files-to-google-colab-4d29ffa9db85\n",
        "#drive.mount('/content/drive')\n",
        "path=\"/content/drive/My Drive/Classroom/Huawei HCIA-AI - Turma 01 2020\"\n",
        "df=pd.read_csv(path+\"/golf.txt\")\n",
        "#df=pd.read_csv(path+\"/golf4.txt\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ot9RalQ1y-2w"
      },
      "source": [
        "### 3.2.2 Superparameter definition section\n",
        "Here you can choose to use Classification tree or Regression tree. \n",
        "\n",
        "1. Specifies the address of\n",
        "the dataset.\n",
        "2. Get feature name. \n",
        "3. Determine whether the algorithm matches the data set algorithm \n",
        "- Regression\n",
        "- Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p4f-D9xyzZr2"
      },
      "source": [
        "algorithm = \"Classification\" # Algorithm: Classification, Regression\n",
        "\n",
        "# This dictionary is used to store feature types of continuous numeric features and discrete literal features for subsequent judgment\n",
        "dataset_features = dict()\n",
        "num_of_columns = df.shape[1]-1\n",
        "#The data type of each column of the data is saved for displaying the data name \n",
        "for i in range(0, num_of_columns):\n",
        "  #Gets the column name and holds the characteristics of a column of data by column \n",
        "  column_name = df.columns[i]\n",
        "  #Save the type of the data\n",
        "  dataset_features[column_name] = df[column_name].dtypes\n",
        "# The size of the indent when display \n",
        "root = 1\n",
        "# If the algorithm selects a regression tree but the label is not a continuous value, an error is reported \n",
        "if algorithm == 'Regression':\n",
        "  if df['Decision'].dtypes == 'object': raise ValueError('dataset wrong')\n",
        "# If the tag value is continuous, the regression tree must be used \n",
        "if df['Decision'].dtypes != 'object':\n",
        "  algorithm = 'Regression'\n",
        "  global_stdev = df['Decision'].std(ddof=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gs1GtNFx0NAG"
      },
      "source": [
        "### 3.2.3 Define the functions required to complete the algorithm\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6C2PjODnAgq7"
      },
      "source": [
        "### ProcessContinuousFeatures\n",
        "Used to convert a continuous digital feature into a category feature.\n",
        "In case feature values are continuous then they are discretized using the following function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QSaYKN200SD5"
      },
      "source": [
        "# This function is used to handle numeric characteristics\n",
        "def processContinuousFeatures(cdf, column_name, entropy):\n",
        "  # Numerical features are arranged in order \n",
        "  unique_values = sorted(cdf[column_name].unique())\n",
        "  subset_ginis = [];\n",
        "  subset_red_stdevs = []\n",
        "  for i in range(0, len(unique_values) - 1):\n",
        "    threshold = unique_values[i]\n",
        "    # Find the segmentation result if the first number is used as the threshold \n",
        "    subset1 = cdf[cdf[column_name] <= threshold]\n",
        "    subset2 = cdf[cdf[column_name] > threshold]\n",
        "    # Calculate the proportion occupied by dividing the two parts \n",
        "    subset1_rows = subset1.shape[0];\n",
        "    subset2_rows = subset2.shape[0]\n",
        "    total_instances = cdf.shape[0]\n",
        "    # In the text feature part, entropy is calculated by using the cycle,\n",
        "    # and in the numeric part, entropy is calculated by using the two groups after segmentation,\n",
        "    # and the degree of entropy reduction is obtained\n",
        "    if algorithm == 'Classification':\n",
        "      decision_for_subset1 = subset1['Decision'].value_counts().tolist() \n",
        "      decision_for_subset2 = subset2['Decision'].value_counts().tolist()\n",
        "      gini_subset1 = 1; gini_subset2 = 1\n",
        "      for j in range(0, len(decision_for_subset1)):\n",
        "        gini_subset1 = gini_subset1 - math.pow((decision_for_subset1[j] / subset1_rows), 2)\n",
        "      for j in range(0, len(decision_for_subset2)):\n",
        "        gini_subset2 = gini_subset2 - math.pow((decision_for_subset2[j] / subset2_rows), 2)\n",
        "      gini = (subset1_rows / total_instances) * gini_subset1 + (subset2_rows / total_instances) * gini_subset2\n",
        "      subset_ginis.append(gini)\n",
        "    # Take standard deviation as the judgment basis, calculate the decrease value of standard deviation at this time\n",
        "    elif algorithm == 'Regression':\n",
        "      superset_stdev = cdf['Decision'].std(ddof=0) \n",
        "      subset1_stdev = subset1['Decision'].std(ddof=0) \n",
        "      subset2_stdev = subset2['Decision'].std(ddof=0)\n",
        "      threshold_weighted_stdev = (subset1_rows / total_instances) * subset1_stdev + ( subset2_rows / total_instances) * subset2_stdev\n",
        "      threshold_reducted_stdev = superset_stdev - threshold_weighted_stdev \n",
        "      subset_red_stdevs.append(threshold_reducted_stdev)\n",
        "      #Find the index of the split value \n",
        "  if algorithm == \"Classification\":\n",
        "    winner_one = subset_ginis.index(min(subset_ginis)) \n",
        "  elif algorithm == \"Regression\":\n",
        "    winner_one = subset_red_stdevs.index(max(subset_red_stdevs)) \n",
        "  # Find the corresponding value according to the index \n",
        "  winner_threshold = unique_values[winner_one]\n",
        "  # Converts the original data column to an edited string column.\n",
        "  # Characters smaller than the threshold are modified with the <= threshold value \n",
        "  cdf[column_name] = np.where(cdf[column_name] <= winner_threshold, \"<=\" + str(winner_threshold),\">\" + str(winner_threshold))\n",
        "  return cdf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caMHXSJu1SA9"
      },
      "source": [
        "### CalculateEntropy\n",
        "Used to calculate Gini or variances, they are the criteria for classifying."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1vbKk4y1S5h"
      },
      "source": [
        "# This function calculates the entropy of the column, and the input data must contain the Decision column \n",
        "def calculateEntropy(df):\n",
        "  # The regression tree entropy is 0 \n",
        "  if algorithm == 'Regression':\n",
        "    return 0\n",
        "  rows = df.shape[0]\n",
        "  # Use Value_counts to get all values stored as dictionaries, keys: finds keys, and Tolist: change to lists.\n",
        "  #This line of code finds the tag value.\n",
        "  decisions = df['Decision'].value_counts().keys().tolist()\n",
        "  entropy = 0\n",
        "  # Here the loop traverses all the tags \n",
        "  for i in range(0, len(decisions)):\n",
        "    # Record the number of times the tag value appears \n",
        "    num_of_decisions = df['Decision'].value_counts().tolist()[i] \n",
        "    # probability of occurrence\n",
        "    class_probability = num_of_decisions / rows\n",
        "    # Calculate the entropy and sum it up\n",
        "    entropy = entropy - class_probability * math.log(class_probability, 2) \n",
        "  return entropy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yujaBZCi15Da"
      },
      "source": [
        "### FindDecision\n",
        "Find which feature in the current data to classify"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QsrtmWP152m"
      },
      "source": [
        "# The main purpose of this function is to traverse the entire column of the table, \n",
        "# find which column is the best split column, and return the name of the column \n",
        "def findDecision(ddf):\n",
        "  \n",
        "  # If it's a regression tree, then you take the standard deviation of the true value \n",
        "  if algorithm == 'Regression':\n",
        "    stdev = ddf['Decision'].std(ddof=0)\n",
        "  #Get the entropy of the decision column \n",
        "  entropy = calculateEntropy(ddf)\n",
        "  \n",
        "  columns = ddf.shape[1];\n",
        "  rows = ddf.shape[0]\n",
        "  \n",
        "  # Used to store Gini and standard deviation values\n",
        "  ginis = [];\n",
        "  reducted_stdevs = []\n",
        "  # Traverse all columns and calculate the relevant indexes of all columns according to algorithm selection\n",
        "  for i in range(0, columns - 1):\n",
        "    column_name = ddf.columns[i] \n",
        "    column_type = ddf[column_name].dtypes\n",
        "\n",
        "    # Determine if the column feature is a number, and if so, process the data using the following function,\n",
        "    # which modifies the data to a string type category on return.\n",
        "    # The idea is to directly use character characteristics, continuous digital characteristics into discrete character characteristics \n",
        "    if column_type != 'object':\n",
        "      ddf = processContinuousFeatures(ddf, column_name, entropy)\n",
        "    # The statistical data in this column can be obtained, and the continuous data can be directly\n",
        "    #classified after processing,\n",
        "    # and the categories are less than the threshold and greater than the threshold \n",
        "    classes = ddf[column_name].value_counts()\n",
        "    gini = 0;\n",
        "    weighted_stdev = 0\n",
        "    # Start the loop with the type of data in the column\n",
        "    for j in range(0, len(classes)):\n",
        "      current_class = classes.keys().tolist()[j]\n",
        "      # The final classification result corresponding to the data is selected \n",
        "      # by deleting the value of the df column equal to the current data \n",
        "      subdataset = ddf[ddf[column_name] == current_class]\n",
        "\n",
        "      subset_instances = subdataset.shape[0]\n",
        "      # The entropy of information is calculated here \n",
        "      if algorithm == 'Classification': # GINI index\n",
        "        decision_list = subdataset['Decision'].value_counts().tolist()\n",
        "\n",
        "        subgini = 1\n",
        "\n",
        "        for k in range(0, len(decision_list)):\n",
        "          #decision_list[k] / subset_instances= probability that the sample belongs to class k\n",
        "          subgini = subgini - math.pow((decision_list[k] / subset_instances), 2)\n",
        "\n",
        "        gini = gini + (subset_instances / rows) * subgini\n",
        "      # The regression tree is judged by the standard deviation,\n",
        "      # and the standard deviation of the subclasses in this column is calculated here \n",
        "      elif algorithm == 'Regression':\n",
        "        subset_stdev = subdataset['Decision'].std(ddof=0)\n",
        "        weighted_stdev = weighted_stdev + (subset_instances / rows) * subset_stdev\n",
        "\n",
        "    # Used to store the final value of this column \n",
        "    if algorithm == \"Classification\":\n",
        "      ginis.append(gini)\n",
        "    # Store the decrease in standard deviation for all columns \n",
        "    elif algorithm == 'Regression':\n",
        "      reducted_stdev = stdev - weighted_stdev \n",
        "      reducted_stdevs.append(reducted_stdev)\n",
        "\n",
        "  # Determine which column is the first branch\n",
        "  # by selecting the index of the largest value from the list of evaluation indicators \n",
        "  if algorithm == \"Classification\":\n",
        "    winner_index = ginis.index(min(ginis)) \n",
        "  elif algorithm == \"Regression\":\n",
        "    winner_index = reducted_stdevs.index(max(reducted_stdevs)) \n",
        "  winner_name = ddf.columns[winner_index]\n",
        "  return winner_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMyS9gH73xkK"
      },
      "source": [
        "### FormatRule\n",
        "Standardize the final output format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85jdc0bC3yI-"
      },
      "source": [
        "# ROOT is a number used to generate ' 'to adjust the display format of the decision making process \n",
        "def formatRule(root):\n",
        "  resp = ''\n",
        "  for i in range(0, root): \n",
        "    resp = resp + ' '\n",
        "  return resp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdhaYuN_35nO"
      },
      "source": [
        "### BuildDecisionTree\n",
        " Main function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVol6Wag39Db"
      },
      "source": [
        "# With this function, you build the decision tree model,\n",
        "# entering data in dataframe format, the root value, and the file address\n",
        "# If the value in the column is literal, it branches directly by literal category \n",
        "def buildDecisionTree(df, root):\n",
        "  \n",
        "  # Identify the different charForResp \n",
        "  charForResp = \"'\"\n",
        "  if algorithm == 'Regression':\n",
        "    charForResp = \"\"\n",
        "\n",
        "  tmp_root = root * 1\n",
        "\n",
        "  df_copy = df.copy()\n",
        "  \n",
        "  # Output the winning column of the decision tree, enter a list,\n",
        "  # and output the column name of the decision column in the list \n",
        "  winner_name = findDecision(df)\n",
        "  # Determines whether the winning column is a number or a character \n",
        "  numericColumn = False\n",
        "  if dataset_features[winner_name] != 'object':\n",
        "    numericColumn = True\n",
        "  # To ensure the integrity of the original data and prevent the data from changing,\n",
        "  # mainly to ensure that the data of other columns besides the winning column does not change, \n",
        "  # so as to continue the branch in the next step.\n",
        "  columns = df.shape[1]\n",
        "  for i in range(0, columns - 1):\n",
        "    column_name = df.columns[i]\n",
        "    if df[column_name].dtype != 'object' and column_name != winner_name:\n",
        "      df[column_name] = df_copy[column_name]\n",
        "  # Find the element in the branching column\n",
        "  classes = df[winner_name].value_counts().keys().tolist()\n",
        "  # Traversing all classes in the branch column has two functions:\n",
        "  # 1. Display which class is currently traversed to; 2. Determine whether the current class is \n",
        "  #already leaf node\n",
        "  for i in range(0, len(classes)):\n",
        "    # Find the Subdataset as in FindDecision, but discard this column of the current branch \n",
        "    current_class = classes[i]\n",
        "    subdataset = df[df[winner_name] == current_class]\n",
        "    # At the same time, the data of the first branch column is discarded and the remaining data is processed\n",
        "    subdataset = subdataset.drop(columns=[winner_name])\n",
        "    # Edit the display situation. If it is a numeric feature, the character conversion has been\n",
        "    #completed when searching for branches.\n",
        "    #If it is not a character feature, it is displayed with column names \n",
        "    if numericColumn == True:\n",
        "      compareTo = current_class # current class might be <=x or >x in this case\n",
        "    else:\n",
        "      compareTo = \" == '\" + str(current_class) + \"'\"\n",
        "\n",
        "    terminateBuilding = False\n",
        "\n",
        "    # -----------------------------------------------\n",
        "    # This determines whether it is already the last leaf node \n",
        "    if len(subdataset['Decision'].value_counts().tolist()) == 1:\n",
        "      final_decision = subdataset['Decision'].value_counts().keys().tolist()[ 0] # all items are equal in this case\n",
        "      terminateBuilding = True\n",
        "    # At this time, only the Decision column is left, that is, all the segmentation features have been used\n",
        "    elif subdataset.shape[1] == 1:\n",
        "      # get the most frequent one\n",
        "      final_decision = subdataset['Decision'].value_counts().idxmax() \n",
        "      terminateBuilding = True\n",
        "    # The regression tree is judged as leaf node if the number of elements is less than 5\n",
        "    #elif algorithm == 'Regression' and subdataset.shape[0] < 5: # pruning condition\n",
        "    # Another criterion is to take the standard deviation as the criterion and the sample mean in the\n",
        "    #node as the value of the node\n",
        "    elif algorithm == 'Regression' and subdataset['Decision'].std(ddof=0)/global_stdev < 0.4:\n",
        "      # get average\n",
        "      final_decision = subdataset['Decision'].mean()\n",
        "      terminateBuilding = True\n",
        "    # -----------------------------------------------\n",
        "    # Here we begin to output the branching results of the decision tree.ã€‚\n",
        "    # Print the if rule\n",
        "    print(formatRule(root), \"if \", winner_name, compareTo, \":\")\n",
        "    # ----------------------------------------------- \n",
        "    # check decision is made\n",
        "    # print leaf node\n",
        "    if terminateBuilding == True:\n",
        "      print(formatRule(root + 1), \"return \", charForResp + str(final_decision) + charForResp) \n",
        "      \n",
        "    else:# decision is not made, continue to create branch and leafs\n",
        "      # The size of the indent at display represented by root \n",
        "      root = root + 1\n",
        "      # Call this function again for the next loop \n",
        "      buildDecisionTree(subdataset, root)\n",
        "    root = tmp_root * 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N3SOfR450EU"
      },
      "source": [
        "### 3.2.4 Execute the code"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fF3_Lken52EW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "dd4ce78c-0562-41fb-ae07-03ae8b1eaae8"
      },
      "source": [
        "#call the function\n",
        "buildDecisionTree(df,root)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  if  Outlook  == 'Rain' :\n",
            "   if  Temp.  == '>69' :\n",
            "    if  Wind  == 'Weak' :\n",
            "     return  '46'\n",
            "    if  Wind  == 'Strong' :\n",
            "     return  '30'\n",
            "   if  Temp.  == '<=69' :\n",
            "    if  Humidity  == '>75' :\n",
            "     return  '52'\n",
            "    if  Humidity  == '<=75' :\n",
            "     return  '25'\n",
            "  if  Outlook  == 'Sunny' :\n",
            "   if  Humidity  == '>75' :\n",
            "    if  Wind  == 'Weak' :\n",
            "     if  Temp.  == '>69' :\n",
            "      return  '35'\n",
            "    if  Wind  == 'Strong' :\n",
            "     return  '30'\n",
            "   if  Humidity  == '<=75' :\n",
            "    if  Temp.  == '<=69' :\n",
            "     return  '37'\n",
            "    if  Temp.  == '>69' :\n",
            "     return  '48'\n",
            "  if  Outlook  == 'Overcast' :\n",
            "   if  Humidity  == '>75' :\n",
            "    if  Wind  == 'Strong' :\n",
            "     return  '51'\n",
            "    if  Wind  == 'Weak' :\n",
            "     return  '46'\n",
            "   if  Humidity  == '<=75' :\n",
            "    return  '43'\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}